# Fly.io configuration for EndoScribe with 
# 12/21/25: original config had GPU support; removed since we moved to managed models
# Documentation: https://fly.io/docs/reference/configuration/

app = "endoscribe-local"
primary_region = "ord"  # Chicago - only region with A10 GPUs

# Kill signal and grace period
kill_signal = "SIGINT"
kill_timeout = "60s"

[build]

[env]
  PORT = "8000"
  PYTHONUNBUFFERED = "1"

# NVIDIA A10 GPU (24GB VRAM); Sufficient for WhisperX large-v3 model
[vm]
  #size = "a10" # gpu for local models
  size = "shared-cpu-2x"
  memory = "4gb"

# Persistent volumes for model caching and data storage
# Note: Volumes must be created with GPU constraints before deployment:
#   fly volumes create data --size 30 --vm-gpu-kind a10 --region ord
# NON GPU: fly volumes create datanongpu --size 30 --region ord --app endoscribe-local
[[mounts]]
  #source = "data"
  source = "datanongpu"
  destination = "/data"

# HTTP service configuration
[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = "suspend"   # suspend machines when idle
  auto_start_machines = true     # Start machines on incoming requests
  min_machines_running = 1

  # Connection limits
  # soft_limit = 1 for scale-to-zero: wake single machine faster
  [http_service.concurrency]
    type = "requests"
    hard_limit = 10
    soft_limit = 1

# WebSocket support for real-time transcription
# Fly Proxy will handle WebSocket upgrades automatically

# Note: Health checks removed to prevent keeping machine alive
# App implements custom idle timeout (60s) for faster scale-down
# See web_app/server.py for idle shutdown logic
